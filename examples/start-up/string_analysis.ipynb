{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Simulation Analysis\n",
    "\n",
    "This notebook will help you analyse the convergence of the string-method and if you are lucky extract a nice free energy surface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob as glob\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, AutoMinorLocator\n",
    "from MDAnalysis.analysis.align import AlignTraj\n",
    "import MDAnalysis as mda\n",
    "import nglview as nv\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pyemma\").setLevel(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorbar(mappable, cmap, norm, label0, size=10):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm=norm)\n",
    "    cbar.set_label(label0, size=size)\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.facecolor\"] = \"#f9f9fb\"\n",
    "plt.rcParams[\"grid.color\"] = \"white\"\n",
    "plt.rcParams[\"grid.linestyle\"] = \"-\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 2\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"lines.solid_capstyle\"] = \"round\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort(l):\n",
    "    \"\"\"\n",
    "    Takes as input a list l of strings and sorts it with natural order.\n",
    "      Parameters\n",
    "      ----------\n",
    "      l: list of strings.\n",
    "      Returns\n",
    "      -------\n",
    "      l sorted\n",
    "    \"\"\"\n",
    "    from re import split\n",
    "\n",
    "    assert isinstance(l, list), \"l is not a list!\"\n",
    "    for i in l:\n",
    "        assert isinstance(i, str), \"List contains non-string elements.\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in split(\"([0-9]+)\", key)]\n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Convergence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract CVs\n",
    "\n",
    "In the cell bellow you can select which will be the simulation directory (in case this notebook is elsewhere). If the notebook is in the simulation directory just leave it as \".\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_directory = \".\"\n",
    "os.chdir(simulation_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the strings in the `strings` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = natural_sort(glob.glob(\"./strings/string*txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = np.array([np.loadtxt(file).T for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv.pkl\", \"rb\") as file:\n",
    "    cvs, ndx_groups = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"String details\")\n",
    "print(\"\")\n",
    "print(f\"Number of string: {strings.shape[0]}\")\n",
    "print(f\"Number of cvs: {strings.shape[1]}\")\n",
    "print(f\"Number of beads per string: {strings.shape[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze string convergence\n",
    "In these next plots you will be able to study the convergence of the string. At convergence the strings should be oscillating around an equilibrium position and not drift over the different iterations.\n",
    "\n",
    "## Strings as a function of time\n",
    "In this plot we can see the evolution of each string CV as function of the timeration number separatelly.\n",
    "\n",
    "You can change two parameters in these plots the `start_iteration` before which all data is not plotted and the `n_average` which is the number of strings iterations to average in one block of strings. This is done in order to cancel some of the noisyness in the representation, to reduce the number of strings in the plot and to see more clearly if there is average drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ borrar Ãºltimo string\n",
    "+ probar con el GPCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iteration = 50\n",
    "n_average = 5\n",
    "\n",
    "\n",
    "n_plots = strings.shape[1]\n",
    "n_strings = strings.shape[0]\n",
    "fig, ax = plt.subplots(ceil(n_plots / 2), 2, figsize=(20, 8 * ceil(n_plots / 2)))\n",
    "ax = ax.flatten()\n",
    "cmap = plt.cm.viridis_r\n",
    "n_colors = (n_strings - start_iteration) // n_average + 1\n",
    "colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=start_iteration, vmax=n_strings)\n",
    "\n",
    "for i, a in enumerate(ax[:n_plots]):\n",
    "    a.plot(strings[0, i, :], ls=\":\", marker=\".\", label=\"string0\", color=\"k\")\n",
    "    for jj, j in enumerate(range(start_iteration, n_strings, n_average)):\n",
    "        string = np.mean(strings[j : j + n_average, i, :], axis=0)\n",
    "        a.plot(string, ls=\"-\", marker=\"o\", color=colors[jj])\n",
    "    av = np.mean(strings[start_iteration:, i, :], axis=0)\n",
    "    std = np.std(strings[start_iteration:, i, :], axis=0)\n",
    "    a.fill_between(\n",
    "        np.arange(len(av)),\n",
    "        av + std,\n",
    "        av - std,\n",
    "        alpha=0.4,\n",
    "        label=f\"std(string{start_iteration}-{n_strings})\",\n",
    "    )\n",
    "    a.plot(\n",
    "        av,\n",
    "        ls=\"-\",\n",
    "        marker=\".\",\n",
    "        color=\"k\",\n",
    "        label=f\"mean(string{start_iteration}-{n_strings})\",\n",
    "    )\n",
    "    a.set_ylabel(\n",
    "        f\"{list(ndx_groups.keys())[2*i]} - {list(ndx_groups.keys())[2*i+1]} (nm)\",\n",
    "        size=18,\n",
    "        labelpad=16,\n",
    "    )\n",
    "    a.set_xlabel(\"bead number\", size=15, labelpad=13)\n",
    "    a.set_xlim(left=0, right=strings.shape[2] - 1)\n",
    "    a.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    a.xaxis.set_major_locator(MultipleLocator(1))\n",
    "    a.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    a.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    a.grid(which=\"minor\")\n",
    "    a.tick_params(axis=\"y\", labelsize=14)\n",
    "    a.tick_params(axis=\"x\", labelsize=11)\n",
    "    if i % 2 != 0:\n",
    "        a.legend()\n",
    "        cbar = colorbar(a, cmap, norm, \"iteration number\", 20)\n",
    "if n_plots % 2:\n",
    "    fig.delaxes(ax[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of beads with iterations\n",
    "\n",
    "In this plot the trajectory of beads cvs over iterations is presented. You can observe if the beads are stable or drifting in some direction. In this plot you can choose one parameter, `n_rolling_average`, which determines the size of the rolling average window applied to smooth-out the noisyness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rolling_average = 20\n",
    "\n",
    "n_strings = strings.shape[0]\n",
    "n_cvs = strings.shape[1]\n",
    "n_beads = strings.shape[2]\n",
    "cmap = plt.cm.viridis_r\n",
    "colors = cmap(np.linspace(0, 1, n_beads - 1))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=n_beads - 1)\n",
    "fig, ax = plt.subplots(ceil(n_cvs / 2), 2, figsize=(20, 8 * ceil(n_cvs / 2)))\n",
    "ax = ax.flatten()\n",
    "for i in range(n_cvs):\n",
    "    for j in range(1, n_beads - 1):\n",
    "        y = np.convolve(\n",
    "            strings[:, i, j],\n",
    "            np.ones((n_rolling_average,)) / n_rolling_average,\n",
    "            mode=\"valid\",\n",
    "        )\n",
    "        x = np.arange(n_strings)[n_rolling_average - 1 :]\n",
    "        ax[i].plot(x, y, color=colors[j])\n",
    "        ax[i].set_ylabel(\n",
    "            f\"{list(ndx_groups.keys())[2*i]} - {list(ndx_groups.keys())[2*i+1]} (nm)\",\n",
    "            size=18,\n",
    "            labelpad=16,\n",
    "        )\n",
    "        ax[i].set_xlabel(\"iteration number\", size=15, labelpad=13)\n",
    "        ax[i].yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "        ax[i].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        ax[i].grid(which=\"minor\")\n",
    "        ax[i].tick_params(axis=\"y\", labelsize=14)\n",
    "        ax[i].tick_params(axis=\"x\", labelsize=11)\n",
    "    if i % 2 != 0:\n",
    "        ax[i].legend()\n",
    "        cbar = colorbar(ax[i], cmap, norm, \"bead number\", 20)\n",
    "if n_plots % 2:\n",
    "    fig.delaxes(ax[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution over iterations of pairs of cvs\n",
    "In this plot you can see the evolution of the string with iterations projected onto two chosen cvs. The plots are just like in the previous section.\n",
    "\n",
    "You can choose your pair of cvs with the variables `cv_0` and `cv_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CV numbers\")\n",
    "ndx_groups_list = list(ndx_groups)\n",
    "for i, cv in enumerate(cvs):\n",
    "    print(f\"CV {i} is {ndx_groups_list[cv[0]-1]} - {ndx_groups_list[cv[1]-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_0 = 3\n",
    "cv_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iteration = 50\n",
    "n_average = 10\n",
    "\n",
    "n_strings = strings.shape[0]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "cmap = plt.cm.viridis_r\n",
    "n_colors = (n_strings - start_iteration) // n_average + 1\n",
    "colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=start_iteration, vmax=n_strings)\n",
    "ax.plot(\n",
    "    strings[0, cv_0, :],\n",
    "    strings[0, cv_1, :],\n",
    "    ls=\":\",\n",
    "    marker=\".\",\n",
    "    label=\"string0\",\n",
    "    color=\"k\",\n",
    ")\n",
    "av_0 = np.mean(strings[start_iteration:, cv_0, :], axis=0)\n",
    "std_0 = np.std(strings[start_iteration:, cv_0, :], axis=0)\n",
    "av_1 = np.mean(strings[start_iteration:, cv_1, :], axis=0)\n",
    "std_1 = np.std(strings[start_iteration:, cv_1, :], axis=0)\n",
    "ax.plot(\n",
    "    av_0,\n",
    "    av_1,\n",
    "    ls=\"-\",\n",
    "    marker=\".\",\n",
    "    color=\"k\",\n",
    "    label=f\"mean(string{start_iteration}-{n_strings})\",\n",
    ")\n",
    "\n",
    "for jj, j in enumerate(range(start_iteration, n_strings, n_average)):\n",
    "    av_0 = np.mean(strings[j:, cv_0, :], axis=0)\n",
    "    std_0 = np.std(strings[j:, cv_0, :], axis=0)\n",
    "    av_1 = np.mean(strings[j:, cv_1, :], axis=0)\n",
    "    std_1 = np.std(strings[j:, cv_1, :], axis=0)\n",
    "    ax.errorbar(\n",
    "        av_0, av_1, fmt=\"--\", xerr=std_0, yerr=std_1, color=colors[jj], alpha=0.9\n",
    "    )\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    f\"{ndx_groups_list[cv_1*2]} - {ndx_groups_list[cv_1*2+1]} (nm)\",\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "ax.set_xlabel(\n",
    "    f\"{ndx_groups_list[cv_0*2]} - {ndx_groups_list[cv_0*2+1]} (nm)\",\n",
    "    size=18,\n",
    "    labelpad=16,\n",
    ")\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.grid(which=\"minor\")\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=11)\n",
    "ax.legend()\n",
    "cbar = colorbar(ax, cmap, norm, \"iteration number\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution over CVs that are a function of the cvs\n",
    "\n",
    "If you are interested in studying the convergence of cvs that are a function of CVs (for example averaging over symmetrical distances). You can construct a `reduced_string` array in which cvs are a function of the cvs used for the string method. In the example bellow, we produce two cvs which are the mean of cvs used in the string method simulation. Then, similar plotting as before can be done. \n",
    "\n",
    "In addition if you are interested in the convergence of some other cv which is not a function of the cvs used in the string method you can also study them! Just extract the average value of that particular CV in the `md/*/*/restrained/traj_comp.xtc` for all the restrained simulation and shape them into an `reduced_string` numpy array with shape (n_iterations, n_cvs, n_beads).\n",
    "\n",
    "If this sort of analysis is meaningless in your system, for example because the chosen cvs are very diagnostic, please ignore this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_string = np.hstack(\n",
    "    [\n",
    "        np.mean(strings[:, 0:2, :], axis=1, keepdims=True),\n",
    "        np.mean(strings[:, 6:, :], axis=1, keepdims=True),\n",
    "    ]\n",
    ")\n",
    "reduced_string_labels = [\"X (nm)\", \"Y (nm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iteration = 100\n",
    "n_average = 40\n",
    "\n",
    "n_strings = strings.shape[0]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "cmap = plt.cm.viridis_r\n",
    "n_colors = (n_strings - start_iteration) // n_average + 1\n",
    "colors = cmap(np.linspace(0, 1, n_colors))  # yellow to blue\n",
    "norm = mpl.colors.Normalize(vmin=start_iteration, vmax=n_strings)\n",
    "ax.plot(\n",
    "    reduced_string[0, 0, :],\n",
    "    reduced_string[0, 1, :],\n",
    "    ls=\":\",\n",
    "    marker=\".\",\n",
    "    label=\"string0\",\n",
    "    color=\"k\",\n",
    ")\n",
    "av_0 = np.mean(reduced_string[start_iteration:, 0, :], axis=0)\n",
    "std_0 = np.std(reduced_string[start_iteration:, 0, :], axis=0)\n",
    "av_1 = np.mean(reduced_string[start_iteration:, 1, :], axis=0)\n",
    "std_1 = np.std(reduced_string[start_iteration:, 1, :], axis=0)\n",
    "ax.plot(\n",
    "    av_0,\n",
    "    av_1,\n",
    "    ls=\"-\",\n",
    "    marker=\".\",\n",
    "    color=\"k\",\n",
    "    label=f\"mean(string{start_iteration}-{n_strings})\",\n",
    ")\n",
    "\n",
    "for jj, j in enumerate(range(start_iteration, n_strings, n_average)):\n",
    "    av_0 = np.mean(reduced_string[j:, 0, :], axis=0)\n",
    "    std_0 = np.std(reduced_string[j:, 0, :], axis=0)\n",
    "    av_1 = np.mean(reduced_string[j:, 1, :], axis=0)\n",
    "    std_1 = np.std(reduced_string[j:, 1, :], axis=0)\n",
    "    ax.errorbar(\n",
    "        av_0, av_1, fmt=\"--\", xerr=std_0, yerr=std_1, color=colors[jj], alpha=0.9\n",
    "    )\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    reduced_string_labels[1], size=18, labelpad=16,\n",
    ")\n",
    "ax.set_xlabel(\n",
    "    reduced_string_labels[0], size=18, labelpad=16,\n",
    ")\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.grid(which=\"minor\")\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.tick_params(axis=\"x\", labelsize=11)\n",
    "ax.legend()\n",
    "cbar = colorbar(ax, cmap, norm, \"iteration number\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have been able to install correctly [NGLview](https://github.com/nglviewer/nglview) in this jupyter-lab, which is tricky sometimes, you can visualize the `md/iter/*/restrained/confout.gro` (in ribbon, green) files. `iteration` is the iteration you want to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 5\n",
    "beads = natural_sort(glob.glob(f\"md/{iteration}/*/restrained\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = mda.Universe(\n",
    "    beads[0] + \"/confout.gro\", [b + \"/confout.gro\" for b in beads], in_memory=True\n",
    ")\n",
    "start = mda.Universe(\"topology/start.gro\")\n",
    "_ = AlignTraj(traj, start, select=\"name CA and protein\", in_memory=True).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = nv.show_mdanalysis(traj, default=False)\n",
    "view.add_ribbon(selection=\"protein\", color=\"green\", component=0)\n",
    "view.center()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes need to run this cell several times to see something. Sometimes it takes a few seconds to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Energy Surface\n",
    "\n",
    "Once your strings are converged, the swarms are sampling over and over the same part of phase space and we can discretrize it and do statistics on the jumps. This will result in a free energy surface along some cv, which may not need to be the ones that parametrize the string. It is very important to keep in mind that a converged string does not imply a converged FES and it might be necessary to do one or two (or more) hundred additional iterations.\n",
    "\n",
    "\n",
    "Now instead of using the data in `strings/string*.xtx` we will use the data in `md/*/*/s*/pullx.xvg` if we want to use the cvs of the string. Otherwise, you add here code that reads `md/*/*/s*/traj_comp.xtc`, calculates your desired cv and then shapes the data into the correct shape `(n_iterations*n_swarms_per_iter*n_beads, n_frames_per_iter, n_cvs)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path of `sys.path.append` should lead to the library `string-method-gmxapi`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")\n",
    "\n",
    "from stringmethod.config import *\n",
    "from stringmethod.postprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_swarm_data(extract, first_iteration=1, last_iteration=None):\n",
    "    if last_iteration == None:\n",
    "        last_iteration = sys.maxsize\n",
    "    if extract:\n",
    "        config = load_config(\"config.json\")\n",
    "\n",
    "        ce = CvValueExtractor.from_config(\n",
    "            config=config,\n",
    "            first_iteration=first_iteration,  # Exclude the first iterations to let the system equilibrate.\n",
    "            last_iteration=last_iteration,  # Usefull to make blocks of the simulation\n",
    "        )\n",
    "        ce.run()\n",
    "        ce.persist()\n",
    "    return np.load(\"postprocessing/cv_coordinates.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_swarm_data` function will load the swarm data in the `cv_coordinates`. If you set `extract=True` it will read the data from the swarm files. If you have done this previously you can set `extract=False` so the function just reads `postprocessing/cv_coordinates.npy`. `first_iteration` can be used to exclude initial swarms as equilibration and `last_iteration` can be done to exclude some iterations for example if you want to estimate the FES convergence by comparing blocks of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coordinates = load_swarm_data(extract=True, first_iteration=1, last_iteration=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the FES that is easy to visualize can only be 1D or 2D we need to reduce the dimensionality of the CVs. For this there are several options:\n",
    "+ You can choose a couple of cvs or one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cvs = [0, 6]\n",
    "cv_coordinates_clean = cv_coordinates[:, :, my_cvs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You can do some function of the cvs, like the mean of several:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coordinates_clean = np.concatenate(\n",
    "    [\n",
    "        np.concatenate([cv_coordinates[:, :, 0:1], cv_coordinates[:, :, 1:2]], axis=0),\n",
    "        np.concatenate([cv_coordinates[:, :, 6:7], cv_coordinates[:, :, 7:8]], axis=0),\n",
    "    ],\n",
    "    axis=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ You can of course make your own function that extracts cvs from the trajectory and makes a cv_coordinates_clean with the correct shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the above cells only run the one you are more interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transition_matrix(\n",
    "    cv_coordinates, n_grid_points=15, T=300, kB=0.0019872041\n",
    "):\n",
    "    config = load_config(\"config.json\")\n",
    "    tc = TransitionCountCalculator.from_config(\n",
    "        config=config,\n",
    "        # You probably want to play around with n_grid_points.\n",
    "        # It sets the resolution. Its optimal value depends on your swarm trajectory length and sample size\n",
    "        n_grid_points=n_grid_points,\n",
    "        cv_coordinates=cv_coordinates,\n",
    "    )\n",
    "    tc.run()\n",
    "    tc.persist()\n",
    "    fc = FreeEnergyCalculator.from_config(\n",
    "        config=config, grid=tc.grid, transition_count=tc.transition_count\n",
    "    )\n",
    "    fc.run()\n",
    "    fc.persist()\n",
    "    return tc.grid, fc.free_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions takes the `cv_coordinates_clean` numpy array and calculates a transition matrix by doing a simple grid on the cv space. It also calculates the probability of transition using the master equation and this results in the calculation of a FES. `n_grid_points` choose the number of grid points of the grid, the coarse the grid the more detailed (and noisy) the FES. This parameter should be varied to obtain an acceptable signal-to-noise ration. The temperature `T` and the value of `kB` can be set too. `kB` is used to give units to the FES. In this example we will use \"kBT\" units since kBT=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, free_energy = calculate_transition_matrix(\n",
    "    cv_coordinates_clean, n_grid_points=20, T=1, kB=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fes(grid, free_energy, fe_cut_off=None, cv_labels=[\"cv0 (nm)\", \"cv1 (nm)\"], f_min=None, f_max=None):\n",
    "    if fe_cut_off == None:\n",
    "        fe_cut_off = sys.maxsize\n",
    "    free_energy[free_energy > fe_cut_off] = np.nan\n",
    "    cv_0 = grid[:, 0]\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    if free_energy.shape[1] == 1:\n",
    "        ax.plot(cv_0, free_energy, \"--o\")\n",
    "        ax.set_ylabel(\"Free Energy (kT)\")\n",
    "    else:\n",
    "        cv_1 = grid[:, 1]\n",
    "        im = plt.contourf(\n",
    "            cv_0,\n",
    "            cv_1,\n",
    "            free_energy.T,\n",
    "            levels=20,\n",
    "        #    norm=mpl.colors.PowerNorm(gamma=1 / 3),\n",
    "            # Used to be rainbow cmap=plt.cm.rainbow\n",
    "            cmap=plt.cm.viridis,\n",
    "            vmin=f_min,\n",
    "            vmax=f_max,\n",
    "        )\n",
    "        cbar = plt.colorbar(im)\n",
    "        cbar.set_label(\"Free Energy (kT)\")\n",
    "        ax.set_ylabel(cv_labels[1])\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax.set_xlabel(cv_labels[0])\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    fig.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function bellow takes the `grid` and `free_energy` arrays from the previous step and plots the free energy surface. The function returns the matplotlib `fig` and `ax` for you to format further if you want. `fe_cut_off` is a maximum value of free energy overwhich nothing is plotted and `cv_labels` are the labels of the cvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = show_fes(\n",
    "    grid, free_energy, fe_cut_off=None, cv_labels=[\"cv0 (nm)\", \"cv1 (nm)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{simulation_directory}/free_energy.svg\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "string_method",
   "language": "python",
   "name": "string_method"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
